{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type-A: TF-IDF & LDA \n",
    "With this version, we are going to perform TF-IDF then LDA.  \n",
    "We can then find similar documents from the corpus.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kejio/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import json \n",
    "import csv\n",
    "import  itertools\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "from smart_open import open\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import TfidfModel\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./data/how-good-is-your-medium-article/test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34645 entries, 0 to 34644\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   _id         34645 non-null  object \n",
      " 1   _timestamp  34645 non-null  float64\n",
      " 2   _spider     34645 non-null  object \n",
      " 3   url         34645 non-null  object \n",
      " 4   domain      34645 non-null  object \n",
      " 5   published   34645 non-null  object \n",
      " 6   title       34645 non-null  object \n",
      " 7   content     34645 non-null  object \n",
      " 8   author      34645 non-null  object \n",
      " 9   image_url   32711 non-null  object \n",
      " 10  tags        34645 non-null  object \n",
      " 11  link_tags   34645 non-null  object \n",
      " 12  meta_tags   34645 non-null  object \n",
      "dtypes: float64(1), object(12)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2keep = ['url', 'title', 'author', 'image_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://medium.com/on-mornings/nocturnalmornin...</td>\n",
       "      <td>For Night Owls, the Day Starts with a Nocturna...</td>\n",
       "      <td>{'name': None, 'url': 'https://medium.com/@HIT...</td>\n",
       "      <td>https://cdn-images-1.medium.com/focal/1200/632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://medium.com/wordsthatmatter/never-break...</td>\n",
       "      <td>Blockchain is Memory – Words That Matter – Medium</td>\n",
       "      <td>{'name': None, 'url': 'https://medium.com/@mar...</td>\n",
       "      <td>https://cdn-images-1.medium.com/max/1200/1*taU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://medium.com/on-mornings/onmorningscredi...</td>\n",
       "      <td>ON MORNINGS Credits – On Mornings – Medium</td>\n",
       "      <td>{'name': None, 'url': 'https://medium.com/@HIT...</td>\n",
       "      <td>https://cdn-images-1.medium.com/max/1200/1*ynE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://medium.com/@LanceUlanoff/apple-homepod...</td>\n",
       "      <td>Apple HomePod Review: Almost love – Lance Ulan...</td>\n",
       "      <td>{'name': None, 'url': 'https://medium.com/@Lan...</td>\n",
       "      <td>https://cdn-images-1.medium.com/max/1200/1*b-Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://blog.medium.com/tips-and-tricks-for-me...</td>\n",
       "      <td>Tips and tricks for Medium writers – 3 min read</td>\n",
       "      <td>{'name': None, 'url': 'https://blog.medium.com...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://medium.com/on-mornings/nocturnalmornin...   \n",
       "1  https://medium.com/wordsthatmatter/never-break...   \n",
       "2  https://medium.com/on-mornings/onmorningscredi...   \n",
       "3  https://medium.com/@LanceUlanoff/apple-homepod...   \n",
       "4  https://blog.medium.com/tips-and-tricks-for-me...   \n",
       "\n",
       "                                               title  \\\n",
       "0  For Night Owls, the Day Starts with a Nocturna...   \n",
       "1  Blockchain is Memory – Words That Matter – Medium   \n",
       "2         ON MORNINGS Credits – On Mornings – Medium   \n",
       "3  Apple HomePod Review: Almost love – Lance Ulan...   \n",
       "4    Tips and tricks for Medium writers – 3 min read   \n",
       "\n",
       "                                              author  \\\n",
       "0  {'name': None, 'url': 'https://medium.com/@HIT...   \n",
       "1  {'name': None, 'url': 'https://medium.com/@mar...   \n",
       "2  {'name': None, 'url': 'https://medium.com/@HIT...   \n",
       "3  {'name': None, 'url': 'https://medium.com/@Lan...   \n",
       "4  {'name': None, 'url': 'https://blog.medium.com...   \n",
       "\n",
       "                                           image_url  \n",
       "0  https://cdn-images-1.medium.com/focal/1200/632...  \n",
       "1  https://cdn-images-1.medium.com/max/1200/1*taU...  \n",
       "2  https://cdn-images-1.medium.com/max/1200/1*ynE...  \n",
       "3  https://cdn-images-1.medium.com/max/1200/1*b-Y...  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns2keep].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the content from the html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html_content(row, column_name='content'): \n",
    "    \"\"\"\n",
    "    Takes in a Row from a pandas DF. \n",
    "    Returns the text from the specified html in the given column-name\n",
    "    \n",
    "    Example: extract_html_content(df.iloc[0], 'content')\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(row[column_name], 'html.parser')\n",
    "    return soup.getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['html_text'] = df.apply(extract_html_content, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', '_timestamp', '_spider', 'url', 'domain', 'published', 'title',\n",
       "       'content', 'author', 'image_url', 'tags', 'link_tags', 'meta_tags',\n",
       "       'html_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34645 entries, 0 to 34644\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   _id         34645 non-null  object \n",
      " 1   _timestamp  34645 non-null  float64\n",
      " 2   _spider     34645 non-null  object \n",
      " 3   url         34645 non-null  object \n",
      " 4   domain      34645 non-null  object \n",
      " 5   published   34645 non-null  object \n",
      " 6   title       34645 non-null  object \n",
      " 7   content     34645 non-null  object \n",
      " 8   author      34645 non-null  object \n",
      " 9   image_url   32711 non-null  object \n",
      " 10  tags        34645 non-null  object \n",
      " 11  link_tags   34645 non-null  object \n",
      " 12  meta_tags   34645 non-null  object \n",
      " 13  html_text   34645 non-null  object \n",
      "dtypes: float64(1), object(13)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save samples with the needed columns as CSVs \n",
    "Samples to save:  \n",
    "* 500 samples  \n",
    "* 1000 samples   \n",
    "* 10000 samples  \n",
    "* 30000 samples  \n",
    "* Whole document  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url', 'title', 'author', 'image_url', 'html_text']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns2keep.append('html_text')\n",
    "columns2keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns2keep].sample(2).to_json('sample.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 20 count saving...\n"
     ]
    }
   ],
   "source": [
    "counts = [20, 1000, 5000, 10000, 25000]\n",
    "for count in counts: \n",
    "    print(f'Starting {count} count saving...')\n",
    "    df[columns2keep].sample(count).to_json(f'./data/samples/sample{count}.json', orient='records')\n",
    "#     df[columns2keep].sample(count).to_csv(f'./data/samples/sample{count}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the whole document.\n",
    "df[columns2keep].sample(frac=1).to_json(f'./data/samples/sampleFull.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Dataset \n",
    "class MyCorpusJSON: \n",
    "    def __init__(self, json_link, column): \n",
    "        # idx is the index of the row where the text content is\n",
    "        self.json_link = json_link \n",
    "        self.text_column = column\n",
    "        self.count = 0\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.count\n",
    "    \n",
    "    def get_nth(self, n): \n",
    "        return next(itertools.islice(self.generator(), n, None))\n",
    "    \n",
    "    def generator(self): \n",
    "        with open(self.json_link) as json_file: \n",
    "            parser = ijson.items(json_file, 'item')\n",
    "            for obj in parser:\n",
    "                yield obj\n",
    "                \n",
    "    def __iter__(self):  \n",
    "        with open(self.json_link) as json_file: \n",
    "            parser = ijson.items(json_file, 'item')\n",
    "            for obj in parser:\n",
    "                self.count += 1\n",
    "                yield obj[self.text_column]\n",
    "        \n",
    "#     def __iter__(self):  \n",
    "#         with open(self.csv_link) as csv_file: \n",
    "#             reader = csv.reader(csv_file)\n",
    "#             next(reader, None)\n",
    "#             for row in reader:\n",
    "#                 self.count += 1\n",
    "#                 print(self.count)\n",
    "#                 if self.count == 398: \n",
    "#                     print(row)\n",
    "#                 yield row[-1]\n",
    "\n",
    "#                 yield row[self.content_idx] # To get the whole doc, use this instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = './data/samples/sample10000.json'\n",
    "text_column = 'html_text'\n",
    "mycorpus = MyCorpusJSON(link, text_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample code. prefix: item.author, item.html_text ...\n",
    "# with open(link) as f: \n",
    "#     parser = ijson.parse(f)\n",
    "#     for prefix, event, value in parser:\n",
    "#         print('prefix={}, event={}, value={}'.format(prefix, event, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of all words in corpus - remove the stopwords in the process\n",
    "dictionary = corpora.Dictionary()\n",
    "# Add document to dictionary \n",
    "for doc in mycorpus: \n",
    "    dictionary.add_documents([doc.lower().split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1115039 unique tokens: ['#1', '#1with', '#3:', '#swissep', '&']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords \n",
    "stop_ids = [\n",
    "    dictionary.token2id[stopword]\n",
    "    for stopword in STOPWORDS\n",
    "    if stopword in dictionary.token2id\n",
    "]\n",
    "# Remove id's that occur once \n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq == 1]\n",
    "dictionary.filter_tokens(once_ids + stop_ids)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(248506 unique tokens: ['#1', '#3:', '&', '(especially', '(in']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('./models/dictionary/sample10000Dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Dataset \n",
    "class BoWCorpusJSON: \n",
    "    def __init__(self, json_link, column, dictionary): \n",
    "        # idx is the index of the row where the text content is\n",
    "        self.json_link = json_link \n",
    "        self.column_name = column\n",
    "        self.count = 0\n",
    "        self.dictionary = dictionary\n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.count\n",
    "        \n",
    "    def __iter__(self):  \n",
    "        with open(self.json_link) as json_file: \n",
    "            parser = ijson.items(json_file, 'item')\n",
    "            for obj in parser:\n",
    "                self.count += 1\n",
    "#                 print(obj['url'])\n",
    "                yield self.dictionary.doc2bow(obj[self.column_name].lower().split())\n",
    "#         with open(self.csv_link) as csv_file: \n",
    "#             reader = csv.reader(csv_file)\n",
    "#             next(reader, None)\n",
    "#             for row in reader:\n",
    "#                 self.count += 1\n",
    "#                 yield dictionary.doc2bow(row[self.content_idx].lower().split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowcorpus = BoWCorpusJSON(link, text_column, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save corpus\n",
    "corpora.MmCorpus.serialize(f'./models/sample10000corpus.mm', bowcorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "loaded_corpus = corpora.MmCorpus('./models/sample10000corpus.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfModel(bowcorpus, dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 2),\n",
       " (12, 2),\n",
       " (13, 1),\n",
       " (14, 2),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 4),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 2),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 1),\n",
       " (38, 2),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 2),\n",
       " (44, 1),\n",
       " (45, 4),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 1),\n",
       " (49, 2),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1),\n",
       " (53, 1),\n",
       " (54, 1),\n",
       " (55, 2),\n",
       " (56, 3),\n",
       " (57, 1),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (60, 2),\n",
       " (61, 3),\n",
       " (62, 1),\n",
       " (63, 1),\n",
       " (64, 1),\n",
       " (65, 3),\n",
       " (66, 2),\n",
       " (67, 1),\n",
       " (68, 1),\n",
       " (69, 1),\n",
       " (70, 1),\n",
       " (71, 1),\n",
       " (72, 2),\n",
       " (73, 1),\n",
       " (74, 1),\n",
       " (75, 1),\n",
       " (76, 1),\n",
       " (77, 1),\n",
       " (78, 1),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (82, 1),\n",
       " (83, 1),\n",
       " (84, 1),\n",
       " (85, 1),\n",
       " (86, 1),\n",
       " (87, 1),\n",
       " (88, 1),\n",
       " (89, 1),\n",
       " (90, 3),\n",
       " (91, 5),\n",
       " (92, 1),\n",
       " (93, 1),\n",
       " (94, 1),\n",
       " (95, 1),\n",
       " (96, 1),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (99, 1),\n",
       " (100, 1),\n",
       " (101, 2),\n",
       " (102, 1),\n",
       " (103, 1),\n",
       " (104, 1),\n",
       " (105, 1),\n",
       " (106, 2),\n",
       " (107, 1),\n",
       " (108, 1),\n",
       " (109, 1),\n",
       " (110, 1),\n",
       " (111, 1),\n",
       " (112, 1),\n",
       " (113, 1),\n",
       " (114, 2),\n",
       " (115, 1),\n",
       " (116, 1),\n",
       " (117, 1),\n",
       " (118, 1),\n",
       " (119, 1),\n",
       " (120, 1),\n",
       " (121, 3),\n",
       " (122, 1),\n",
       " (123, 1),\n",
       " (124, 1),\n",
       " (125, 1),\n",
       " (126, 1),\n",
       " (127, 1),\n",
       " (128, 1),\n",
       " (129, 1),\n",
       " (130, 1),\n",
       " (131, 1),\n",
       " (132, 1),\n",
       " (133, 1),\n",
       " (134, 1),\n",
       " (135, 5),\n",
       " (136, 1),\n",
       " (137, 1),\n",
       " (138, 1),\n",
       " (139, 1),\n",
       " (140, 1),\n",
       " (141, 1),\n",
       " (142, 1),\n",
       " (143, 1),\n",
       " (144, 1),\n",
       " (145, 1),\n",
       " (146, 5),\n",
       " (147, 1),\n",
       " (148, 5),\n",
       " (149, 1),\n",
       " (150, 4),\n",
       " (151, 2),\n",
       " (152, 1),\n",
       " (153, 1),\n",
       " (154, 1),\n",
       " (155, 1),\n",
       " (156, 1),\n",
       " (157, 1),\n",
       " (158, 1),\n",
       " (159, 1),\n",
       " (160, 1),\n",
       " (161, 1),\n",
       " (162, 2),\n",
       " (163, 1),\n",
       " (164, 1),\n",
       " (165, 1),\n",
       " (166, 1),\n",
       " (167, 1),\n",
       " (168, 1),\n",
       " (169, 1),\n",
       " (170, 1),\n",
       " (171, 1),\n",
       " (172, 2),\n",
       " (173, 2),\n",
       " (174, 1),\n",
       " (175, 1),\n",
       " (176, 1),\n",
       " (177, 1),\n",
       " (178, 1),\n",
       " (179, 1),\n",
       " (180, 1),\n",
       " (181, 1),\n",
       " (182, 1),\n",
       " (183, 1),\n",
       " (184, 1),\n",
       " (185, 1),\n",
       " (186, 1),\n",
       " (187, 1),\n",
       " (188, 1),\n",
       " (189, 1),\n",
       " (190, 1),\n",
       " (191, 2),\n",
       " (192, 1),\n",
       " (193, 1),\n",
       " (194, 1),\n",
       " (195, 1),\n",
       " (196, 1),\n",
       " (197, 1),\n",
       " (198, 1),\n",
       " (199, 2),\n",
       " (200, 2),\n",
       " (201, 3),\n",
       " (202, 1),\n",
       " (203, 1),\n",
       " (204, 2),\n",
       " (205, 1),\n",
       " (206, 1),\n",
       " (207, 3),\n",
       " (208, 1),\n",
       " (209, 2),\n",
       " (210, 1),\n",
       " (211, 1),\n",
       " (212, 1),\n",
       " (213, 1),\n",
       " (214, 1),\n",
       " (215, 1),\n",
       " (216, 1),\n",
       " (217, 1),\n",
       " (218, 1),\n",
       " (219, 1),\n",
       " (220, 1),\n",
       " (221, 1),\n",
       " (222, 1),\n",
       " (223, 1),\n",
       " (224, 2),\n",
       " (225, 1),\n",
       " (226, 5),\n",
       " (227, 1),\n",
       " (228, 1),\n",
       " (229, 1),\n",
       " (230, 1),\n",
       " (231, 3),\n",
       " (232, 1),\n",
       " (233, 1),\n",
       " (234, 1),\n",
       " (235, 1),\n",
       " (236, 1),\n",
       " (237, 1),\n",
       " (238, 2),\n",
       " (239, 1),\n",
       " (240, 1),\n",
       " (241, 1),\n",
       " (242, 1),\n",
       " (243, 1),\n",
       " (244, 1),\n",
       " (245, 5),\n",
       " (246, 1),\n",
       " (247, 1),\n",
       " (248, 1),\n",
       " (249, 2),\n",
       " (250, 1),\n",
       " (251, 1),\n",
       " (252, 1),\n",
       " (253, 1),\n",
       " (254, 1),\n",
       " (255, 1),\n",
       " (256, 1),\n",
       " (257, 1),\n",
       " (258, 1),\n",
       " (259, 2),\n",
       " (260, 1),\n",
       " (261, 1),\n",
       " (262, 1),\n",
       " (263, 1),\n",
       " (264, 1),\n",
       " (265, 1),\n",
       " (266, 1),\n",
       " (267, 3),\n",
       " (268, 1),\n",
       " (269, 1),\n",
       " (270, 1),\n",
       " (271, 1),\n",
       " (272, 1),\n",
       " (273, 1),\n",
       " (274, 1),\n",
       " (275, 1),\n",
       " (276, 1),\n",
       " (277, 1),\n",
       " (278, 4),\n",
       " (279, 1),\n",
       " (280, 1),\n",
       " (281, 1),\n",
       " (282, 1),\n",
       " (283, 1),\n",
       " (284, 7),\n",
       " (285, 1),\n",
       " (286, 1),\n",
       " (287, 1),\n",
       " (288, 1),\n",
       " (289, 1),\n",
       " (290, 1),\n",
       " (291, 1),\n",
       " (292, 1),\n",
       " (293, 4),\n",
       " (294, 2),\n",
       " (295, 3),\n",
       " (296, 1),\n",
       " (297, 1),\n",
       " (298, 1),\n",
       " (299, 1),\n",
       " (300, 1),\n",
       " (301, 6),\n",
       " (302, 1),\n",
       " (303, 1),\n",
       " (304, 1),\n",
       " (305, 1),\n",
       " (306, 2),\n",
       " (307, 1),\n",
       " (308, 1),\n",
       " (309, 1),\n",
       " (310, 1),\n",
       " (311, 1),\n",
       " (312, 2),\n",
       " (313, 7),\n",
       " (314, 4),\n",
       " (315, 1),\n",
       " (316, 1),\n",
       " (317, 1),\n",
       " (318, 2),\n",
       " (319, 1),\n",
       " (320, 1),\n",
       " (321, 1),\n",
       " (322, 1),\n",
       " (323, 1),\n",
       " (324, 1),\n",
       " (325, 1),\n",
       " (326, 1),\n",
       " (327, 1),\n",
       " (328, 1),\n",
       " (329, 2),\n",
       " (330, 2),\n",
       " (331, 2),\n",
       " (332, 4),\n",
       " (333, 1),\n",
       " (334, 1),\n",
       " (335, 1),\n",
       " (336, 1),\n",
       " (337, 1),\n",
       " (338, 2),\n",
       " (339, 3),\n",
       " (340, 1),\n",
       " (341, 1),\n",
       " (342, 4),\n",
       " (343, 1),\n",
       " (344, 1),\n",
       " (345, 1),\n",
       " (346, 1),\n",
       " (347, 1),\n",
       " (348, 1),\n",
       " (349, 1),\n",
       " (350, 1),\n",
       " (351, 1),\n",
       " (352, 1),\n",
       " (353, 1),\n",
       " (354, 1),\n",
       " (355, 1),\n",
       " (356, 6),\n",
       " (357, 2),\n",
       " (358, 1),\n",
       " (359, 1),\n",
       " (360, 1),\n",
       " (361, 1),\n",
       " (362, 1),\n",
       " (363, 1),\n",
       " (364, 1),\n",
       " (365, 1),\n",
       " (366, 2),\n",
       " (367, 1),\n",
       " (368, 1),\n",
       " (369, 1),\n",
       " (370, 1),\n",
       " (371, 2),\n",
       " (372, 2),\n",
       " (373, 1),\n",
       " (374, 1),\n",
       " (375, 2),\n",
       " (376, 1),\n",
       " (377, 2)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(bowcorpus.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.008831299994767733),\n",
       " (1, 0.005144301458324677),\n",
       " (2, 0.009658736321516476),\n",
       " (3, 0.01802064487559183),\n",
       " (4, 0.007665093992361952),\n",
       " (5, 0.041020037740073616),\n",
       " (6, 0.043321757661164056),\n",
       " (7, 0.016708361061564984),\n",
       " (8, 0.07879599366879654),\n",
       " (9, 0.01986820939312529),\n",
       " (10, 0.05205051161542952),\n",
       " (11, 0.013188516257622655),\n",
       " (12, 0.013024116204510414),\n",
       " (13, 0.1101841551384785),\n",
       " (14, 0.05699680645572014),\n",
       " (15, 0.012236907357305213),\n",
       " (16, 0.017874567063970764),\n",
       " (17, 0.020510018870036808),\n",
       " (18, 0.01065641273973226),\n",
       " (19, 0.010143731985636869),\n",
       " (20, 0.017350170538476505),\n",
       " (21, 0.016708361061564984),\n",
       " (22, 0.009794112738828912),\n",
       " (23, 0.01732554082115547),\n",
       " (24, 0.03876795106345363),\n",
       " (25, 0.08044440393862709),\n",
       " (26, 0.06138852729198212),\n",
       " (27, 0.012818584653076785),\n",
       " (28, 0.022503661199191335),\n",
       " (29, 0.022503661199191335),\n",
       " (30, 0.04764277420444872),\n",
       " (31, 0.017350170538476505),\n",
       " (32, 0.03269672917836592),\n",
       " (33, 0.03520086843722998),\n",
       " (34, 0.005464210621143038),\n",
       " (35, 0.007337365473839736),\n",
       " (36, 0.017350170538476505),\n",
       " (37, 0.014714718732410459),\n",
       " (38, 0.01618396453607072),\n",
       " (39, 0.2184950864524465),\n",
       " (40, 0.016906799593616992),\n",
       " (41, 0.004716701453055956),\n",
       " (42, 0.007029904122288546),\n",
       " (43, 0.19457010125091626),\n",
       " (44, 0.03269672917836592),\n",
       " (45, 0.058858874929641834),\n",
       " (46, 0.03780088384554303),\n",
       " (47, 0.05453282059567575),\n",
       " (48, 0.009360659796561057),\n",
       " (49, 0.06711720036295749),\n",
       " (50, 0.017350170538476505),\n",
       " (51, 0.007144832935447244),\n",
       " (52, 0.013548512730004677),\n",
       " (53, 0.009609569006271135),\n",
       " (54, 0.020402110824649194),\n",
       " (55, 0.017350170538476505),\n",
       " (56, 0.01986820939312529),\n",
       " (57, 0.027097025460009354),\n",
       " (58, 0.04500732239838267),\n",
       " (59, 0.057085391150203786),\n",
       " (60, 0.01618396453607072),\n",
       " (61, 0.020248464257124857),\n",
       " (62, 0.020510018870036808),\n",
       " (63, 0.01588092473481624),\n",
       " (64, 0.022503661199191335),\n",
       " (65, 0.01175330893290216),\n",
       " (68, 0.014620408057017415),\n",
       " (69, 0.007029904122288546),\n",
       " (70, 0.025442152806511863),\n",
       " (71, 0.03875854480592383),\n",
       " (72, 0.13518055547004906),\n",
       " (73, 0.04764277420444872),\n",
       " (74, 0.08458996114158346),\n",
       " (75, 0.018177606865225248),\n",
       " (76, 0.017119950269775138),\n",
       " (77, 0.01760043421861499),\n",
       " (78, 0.027097025460009354),\n",
       " (79, 0.018177606865225248),\n",
       " (80, 0.017874567063970764),\n",
       " (81, 0.04267491039357112),\n",
       " (82, 0.022503661199191335),\n",
       " (83, 0.018516376540882284),\n",
       " (84, 0.03003551706732988),\n",
       " (85, 0.012673534529083279),\n",
       " (86, 0.015478938934197557),\n",
       " (87, 0.01652273421172776),\n",
       " (88, 0.15480121417122233),\n",
       " (89, 0.01934381286763103),\n",
       " (90, 0.01934381286763103),\n",
       " (91, 0.01760043421861499),\n",
       " (92, 0.06711720036295749),\n",
       " (93, 0.07889811305482805),\n",
       " (94, 0.1544232851376515),\n",
       " (95, 0.010047528438901021),\n",
       " (96, 0.003989586553511211),\n",
       " (97, 0.009229568950714641),\n",
       " (98, 0.020510018870036808),\n",
       " (99, 0.018900441922771516),\n",
       " (100, 0.07135673893775472),\n",
       " (101, 0.017350170538476505),\n",
       " (102, 0.014034813097210075),\n",
       " (103, 0.01155487040085015),\n",
       " (104, 0.01934381286763103),\n",
       " (105, 0.010066513444474654),\n",
       " (106, 0.03868762573526206),\n",
       " (107, 0.0096753139922022),\n",
       " (108, 0.047221780773633634),\n",
       " (109, 0.012319090602637249),\n",
       " (110, 0.017350170538476505),\n",
       " (111, 0.01103047387535589),\n",
       " (112, 0.01618396453607072),\n",
       " (113, 0.022503661199191335),\n",
       " (114, 0.10668727598392778),\n",
       " (115, 0.01760043421861499),\n",
       " (116, 0.01481222698223131),\n",
       " (117, 0.016906799593616992),\n",
       " (118, 0.01142979774343697),\n",
       " (119, 0.007942534736761554),\n",
       " (120, 0.22722999984607434),\n",
       " (121, 0.017874567063970764),\n",
       " (122, 0.020820098033336027),\n",
       " (123, 0.018902990558904178),\n",
       " (124, 0.010431593820790256),\n",
       " (125, 0.12640738374734817),\n",
       " (126, 0.011166813043439349),\n",
       " (127, 0.00809198226803536),\n",
       " (128, 0.021083614448528368),\n",
       " (129, 0.012673534529083279),\n",
       " (130, 0.007599722589741134),\n",
       " (131, 0.014529091882573236),\n",
       " (132, 0.01634836458918296),\n",
       " (133, 0.017350170538476505),\n",
       " (134, 0.014354722260028433),\n",
       " (135, 0.019251729803993776),\n",
       " (136, 0.009436155414282443),\n",
       " (137, 0.02206094775071178),\n",
       " (138, 0.012818584653076785),\n",
       " (139, 0.013887282405661715),\n",
       " (140, 0.02561085466726299),\n",
       " (141, 0.020486530056301376),\n",
       " (142, 0.008721832401722354),\n",
       " (143, 0.020510018870036808),\n",
       " (144, 0.022503661199191335),\n",
       " (145, 0.022503661199191335),\n",
       " (146, 0.022503661199191335),\n",
       " (147, 0.03236792907214144),\n",
       " (148, 0.018691591176553054),\n",
       " (149, 0.04771927758028242),\n",
       " (150, 0.012403691345822539),\n",
       " (151, 0.07560176769108606),\n",
       " (152, 0.01760043421861499),\n",
       " (153, 0.009272605432966428),\n",
       " (154, 0.022503661199191335),\n",
       " (155, 0.011523088664200796),\n",
       " (156, 0.022503661199191335),\n",
       " (157, 0.009451495279452089),\n",
       " (158, 0.059604628179375875),\n",
       " (159, 0.01313266561146609),\n",
       " (160, 0.02133745519678556),\n",
       " (161, 0.01934381286763103),\n",
       " (162, 0.01804709290288614),\n",
       " (163, 0.010775775008676915),\n",
       " (164, 0.013548512730004677),\n",
       " (165, 0.04188030581464449),\n",
       " (167, 0.013362885880167453),\n",
       " (168, 0.016906799593616992),\n",
       " (169, 0.022503661199191335),\n",
       " (170, 0.02133745519678556),\n",
       " (171, 0.014620408057017415),\n",
       " (172, 0.11623273506058589),\n",
       " (173, 0.02133745519678556),\n",
       " (174, 0.02806962619442015),\n",
       " (175, 0.03003551706732988),\n",
       " (176, 0.014620408057017415),\n",
       " (177, 0.013188516257622655),\n",
       " (178, 0.0055342708133473235),\n",
       " (179, 0.01986820939312529),\n",
       " (180, 0.01103047387535589),\n",
       " (181, 0.03025261588124123),\n",
       " (182, 0.02385963879014121),\n",
       " (183, 0.03085218938772569),\n",
       " (184, 0.013816261071292567),\n",
       " (185, 0.012919514935307942),\n",
       " (186, 0.03703275308176457),\n",
       " (187, 0.014034813097210075),\n",
       " (188, 0.02133745519678556),\n",
       " (189, 0.022114459167317475),\n",
       " (190, 0.025839029870615884),\n",
       " (191, 0.1354066900734172),\n",
       " (192, 0.018177606865225248),\n",
       " (193, 0.020510018870036808),\n",
       " (194, 0.05453282059567575),\n",
       " (195, 0.01934381286763103),\n",
       " (196, 0.018177606865225248),\n",
       " (197, 0.01760043421861499),\n",
       " (198, 0.18728150267352559),\n",
       " (199, 0.05554912962264685),\n",
       " (200, 0.036353623373150866),\n",
       " (201, 0.01829076190631407),\n",
       " (202, 0.009321815660048314),\n",
       " (204, 0.018516376540882284),\n",
       " (205, 0.015740593591211213),\n",
       " (206, 0.007069944925349688),\n",
       " (207, 0.02133745519678556),\n",
       " (208, 0.012721076403255932),\n",
       " (209, 0.017874567063970764),\n",
       " (210, 0.032039676599786265),\n",
       " (211, 0.010751502983608616),\n",
       " (212, 0.011857910202104633),\n",
       " (213, 0.015618293580028529),\n",
       " (214, 0.017419845159459185),\n",
       " (215, 0.00924384301426223),\n",
       " (216, 0.06352369893926496),\n",
       " (217, 0.04370349042461367),\n",
       " (218, 0.014714718732410459),\n",
       " (219, 0.010727434074101407),\n",
       " (220, 0.022503661199191335),\n",
       " (221, 0.012139441238308669),\n",
       " (222, 0.01481222698223131),\n",
       " (223, 0.01204117076805555),\n",
       " (224, 0.010028667926062346),\n",
       " (225, 0.01652273421172776),\n",
       " (226, 0.027097025460009354),\n",
       " (227, 0.017350170538476505),\n",
       " (228, 0.018208386716277107),\n",
       " (229, 0.07017406548605037),\n",
       " (230, 0.056701325768314555),\n",
       " (231, 0.016580841600174742),\n",
       " (232, 0.018516376540882284),\n",
       " (233, 0.018516376540882284),\n",
       " (234, 0.0160284554263646),\n",
       " (235, 0.022503661199191335),\n",
       " (236, 0.011369243551012927),\n",
       " (237, 0.0013170689811157939),\n",
       " (238, 0.011280737555494377),\n",
       " (239, 0.015379992934833357),\n",
       " (240, 0.062331986390666214),\n",
       " (241, 0.012721076403255932),\n",
       " (242, 0.10431593820790257),\n",
       " (243, 0.015356528209321978),\n",
       " (244, 0.011523088664200796),\n",
       " (245, 0.046820375668381396),\n",
       " (246, 0.05437482382824884),\n",
       " (247, 0.025678266367206246),\n",
       " (248, 0.34406897589806096),\n",
       " (249, 0.022503661199191335),\n",
       " (250, 0.014529091882573236),\n",
       " (251, 0.01994563455981156),\n",
       " (252, 0.028709444520056866),\n",
       " (253, 0.13334997940163223),\n",
       " (254, 0.00789738125209843),\n",
       " (255, 0.02133745519678556),\n",
       " (256, 0.02222299891198128),\n",
       " (257, 0.01760043421861499),\n",
       " (258, 0.014190322206916198),\n",
       " (259, 0.2813716680446561),\n",
       " (260, 0.010367437601719385),\n",
       " (261, 0.02962445396446262),\n",
       " (262, 0.013816261071292567),\n",
       " (263, 0.009466917396302581),\n",
       " (264, 0.018841793856181194),\n",
       " (265, 0.009201231599313603),\n",
       " (266, 0.01986820939312529),\n",
       " (267, 0.01934381286763103),\n",
       " (268, 0.01244150132751283),\n",
       " (269, 0.015264445145684726),\n",
       " (270, 0.01313266561146609),\n",
       " (271, 0.017874567063970764),\n",
       " (272, 0.004532928433706099),\n",
       " (273, 0.007656840850683126),\n",
       " (274, 0.01934381286763103),\n",
       " (275, 0.022503661199191335),\n",
       " (276, 0.08534982078714223),\n",
       " (277, 0.04500732239838267),\n",
       " (278, 0.010541807224264184),\n",
       " (279, 0.013423440072591495),\n",
       " (280, 0.022503661199191335),\n",
       " (281, 0.012626765727862888),\n",
       " (282, 0.022503661199191335),\n",
       " (283, 0.01760043421861499),\n",
       " (284, 0.010775775008676915),\n",
       " (285, 0.02378728015301438),\n",
       " (286, 0.03520086843722998),\n",
       " (287, 0.01411151678687148),\n",
       " (288, 0.010475173713631726),\n",
       " (289, 0.20196713011306153),\n",
       " (290, 0.010143731985636869),\n",
       " (291, 0.04124085378617006),\n",
       " (292, 0.013548512730004677),\n",
       " (293, 0.20878420170247455),\n",
       " (294, 0.03341672212312997),\n",
       " (295, 0.020863187641580513),\n",
       " (296, 0.01313266561146609),\n",
       " (297, 0.022503661199191335),\n",
       " (298, 0.011280737555494377),\n",
       " (299, 0.01634836458918296),\n",
       " (300, 0.02133745519678556),\n",
       " (301, 0.01934381286763103),\n",
       " (302, 0.020510018870036808),\n",
       " (303, 0.018516376540882284),\n",
       " (304, 0.013816261071292567),\n",
       " (305, 0.011604999371139369),\n",
       " (306, 0.036355213730450496),\n",
       " (307, 0.01986820939312529),\n",
       " (308, 0.22680530307325822),\n",
       " (309, 0.022503661199191335),\n",
       " (310, 0.041020037740073616),\n",
       " (311, 0.020863187641580513),\n",
       " (312, 0.02133745519678556),\n",
       " (313, 0.020220448247377065),\n",
       " (314, 0.013960101938214831),\n",
       " (315, 0.03025261588124123),\n",
       " (316, 0.014271347787550947),\n",
       " (317, 0.017119950269775138),\n",
       " (318, 0.01038866439844437),\n",
       " (319, 0.012971340083394418),\n",
       " (320, 0.041020037740073616),\n",
       " (321, 0.006250921058244108),\n",
       " (322, 0.05280130265584498),\n",
       " (323, 0.007951651124430333),\n",
       " (324, 0.023715820404209265),\n",
       " (325, 0.015740593591211213),\n",
       " (326, 0.017874567063970764),\n",
       " (327, 0.06509906879386192),\n",
       " (328, 0.027150534866855668),\n",
       " (329, 0.011822618742138042),\n",
       " (330, 0.031481187182422425),\n",
       " (332, 0.024807382691645077),\n",
       " (333, 0.04414415619723138),\n",
       " (334, 0.0244209696078326),\n",
       " (335, 0.012818584653076785),\n",
       " (338, 0.017515721308908182),\n",
       " (339, 0.01652273421172776),\n",
       " (340, 0.043064166780085296),\n",
       " (341, 0.007137943787479202),\n",
       " (342, 0.0160284554263646),\n",
       " (343, 0.009036831546201364),\n",
       " (344, 0.018964845303301815),\n",
       " (345, 0.05205051161542952),\n",
       " (346, 0.022503661199191335),\n",
       " (347, 0.023174014496100372),\n",
       " (348, 0.01986820939312529),\n",
       " (349, 0.009077059025744906),\n",
       " (350, 0.01130993798804265),\n",
       " (351, 0.014440585887054685),\n",
       " (352, 0.01934381286763103),\n",
       " (353, 0.00952944633504627),\n",
       " (354, 0.011719270453962387),\n",
       " (355, 0.02133745519678556),\n",
       " (356, 0.013816261071292567),\n",
       " (357, 0.01588092473481624),\n",
       " (358, 0.010066513444474654),\n",
       " (359, 0.008831299994767733),\n",
       " (360, 0.022503661199191335),\n",
       " (361, 0.025510714428736554),\n",
       " (362, 0.01986820939312529),\n",
       " (363, 0.011139023282311563),\n",
       " (364, 0.020510018870036808),\n",
       " (365, 0.020510018870036808),\n",
       " (366, 0.17431493927183284),\n",
       " (367, 0.11920517253815992),\n",
       " (368, 0.007673370884121505),\n",
       " (369, 0.012580745259650904),\n",
       " (370, 0.022503661199191335),\n",
       " (371, 0.01588092473481624),\n",
       " (372, 0.016708361061564984),\n",
       " (373, 0.015126307940620615),\n",
       " (374, 0.01934381286763103),\n",
       " (375, 0.0160284554263646),\n",
       " (376, 0.010163364948567894),\n",
       " (377, 0.00888513721540036),\n",
       " (378, 0.14444949292787831),\n",
       " (379, 0.011685630095017935),\n",
       " (380, 0.01618396453607072),\n",
       " (381, 0.011502121473195593),\n",
       " (382, 0.05369376029036598),\n",
       " (383, 0.02133745519678556),\n",
       " (384, 0.01652273421172776),\n",
       " (385, 0.009201231599313603),\n",
       " (386, 0.02133745519678556),\n",
       " (387, 0.010367437601719385),\n",
       " (388, 0.01934381286763103),\n",
       " (389, 0.015356528209321978),\n",
       " (390, 0.028635879917163935),\n",
       " (391, 0.01501775853366494),\n",
       " (392, 0.029826314528924938),\n",
       " (393, 0.005602043462869111),\n",
       " (394, 0.013024116204510414),\n",
       " (395, 0.06829561244603465),\n",
       " (396, 0.015478938934197557),\n",
       " (397, 0.012580745259650904),\n",
       " (398, 0.01481222698223131),\n",
       " (399, 0.041020037740073616)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model[next(bowcorpus.__iter__())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(bowcorpus.__iter__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a sample text to TFIDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Using machine learning, one can find useful patterns from large data sets to make'\\\n",
    "'data more informative and qualitatively insightful. This is very important for'\\\n",
    "'decision making. Students will be exposed to supervised and unsupervised'\\\n",
    "'learning, respectively.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(794, 0.1122266387490081), (1086, 0.09463764980295794), (1187, 0.07365497550707863), (1220, 0.1113823509375516), (1233, 0.07487090242818138), (1951, 0.21078900333676595), (2150, 0.18722171122505066), (2220, 0.1466336559353409), (4668, 0.16497563946531582), (6429, 0.200468321217535), (9551, 0.2424215949208234), (18140, 0.3954273882327571), (20414, 0.3162519078548135), (24372, 0.3312642171623227), (42351, 0.3830167904661377), (67473, 0.463721994369656)]\n"
     ]
    }
   ],
   "source": [
    "text_words = simple_preprocess(text)\n",
    "tfidf_vec = tfidf_model[dictionary.doc2bow(text_words)]\n",
    "print(tfidf_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(loaded_corpus, num_topics=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the topic distribution for sample text \n",
    "lda_vec = lda_model[dictionary.doc2bow(text_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LDA for similarity index \n",
    "lda_index = similarities.Similarity(None, lda_model[bowcorpus], len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get similar documents from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.Similarity(None, tfidf_model[bowcorpus], len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = index[tfidf_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8703, 0.18585998), (482, 0.16874214), (3962, 0.12512183), (3302, 0.120331176), (4922, 0.110262394), (2055, 0.10742292), (9064, 0.10512229), (672, 0.09871555), (230, 0.09689501), (3049, 0.09573233)]\n"
     ]
    }
   ],
   "source": [
    "# Print top 10 documents \n",
    "print(list(sorted(enumerate(res), key=lambda x: x[1], reverse=True))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://medium.com/iotforall/crash-course-in-machine-learning-4f410018b83',\n",
       " 'title': 'Crash Course in Machine Learning – IoT For All – Medium',\n",
       " 'author': {'name': None,\n",
       "  'url': 'https://medium.com/@narin_luangrath',\n",
       "  'twitter': None},\n",
       " 'image_url': 'https://cdn-images-1.medium.com/max/1200/0*ljnuMGQ0HQIszT0O.jpg',\n",
       " 'html_text': 'Narin LuangrathProduct Engineer at Leverege LLCNov 15, 2017Crash Course in Machine\\xa0LearningPart I: Supervised Machine\\xa0LearningArtificial (Un)intelligenceWhen you type ‘machine learning’ into Google News, the first link you see is a Forbes Magazine piece called “What’s The Difference Between Machine Learning And Artificial Intelligence?” This article contained so many flowery, grandiose descriptions about ML and AI technology that I couldn’t help but laugh. A few notable quotes include:“To get something out of machine learning, you need to know how to code or know someone who does. With artificial intelligence, you get something that takes an idea or a desire and runs with it, curiously seeking out new input and understandings.”“AI models don’t need to be rebuilt: they rebuild themselves. They actively seek out new and better sources of data.”“Your data is your cake mix, and your model is your method.”Addressing each quote in order:AI algorithms (e.g. self-driving cars, video game playing robots) definitely do require coding. The ‘running with desire’ bit sounds like artificial general intelligence…which definitely doesn’t exist.If only this were true, I would never have to work again! One could maybe argue that reinforcement learning algorithms “rebuild” themselves, but a more accurate description would be that they’re “recalibrating”.… if you say so?With all the nonsense used to describe machine learning (ML) and artificial intelligence (AI), it’s time we do a deep dive into what these technologies actually do. First, we need to learn the difference between AI and ML. Fortunately, a fellow writer has already written an excellent explanation here. With that out of the way, we can focus on the ML side of things.By definition, machine learning is the ability for computers to perform tasks without having to be explicitly programed. When writing a “normal” computer program, the coder will manually write out what the program will do, for every possible scenario. An ML program has a different style to it. Typically, the program will combine historical data, complex mathematical models and sophisticated algorithms to deduce the “optimal” behavior.For instance, if you were writing a program to play checkers, a regular program might say something like “if I can jump over an opponent’s piece, then I will do so”. Instead, a machine learning program might say something like, “examine the last 1000 games of checkers I’ve played and pick the move that maximizes the probability that I will win the game”.Most machine learning algorithms fall into one of three categories: supervised learning, unsupervised learning, and reinforcement learning. In this article, we’ll cover just the first of the three.Supervised Machine\\xa0LearningSupervised learning algorithms try to find a formula that accurately predicts the output label from input variables. Let’s clarify what this means with some simple, concrete examples.1. Advertising Example (Linear Regression)Suppose you work for an advertising agency and you want to predict the increased revenue after spending $100 in TV ads. Here, the input variable is advertising cost (TV)and the output label is revenue (Sales). If you had access to historical data about past advertising campaigns you could use a supervised learning algorithm like linear regression to find the answer. The table below lists the dollars spent on TV ads and the resulting sales from 200 advertising campaigns.First, we feed the historical data into our linear regression model. This produces a mathematical formula that predicts sales based on our input variable, TV ad spending:Sales = 7.03 + 0.047(TV)In the above graph, we have plotted both the historical data points (the black dots) as well as the formula our ML algorithm produces (the red line). The equation roughly follows the trajectory of the data points. To answer our original question of expected revenue, we can simply plug $100 in for the variable TV to get,$11.73 = 7.03 + 0.047($100)In other words, after spending 100 dollars on TV advertising, we can expect to generate only $11.73 in sales, based on past data. Therefore, it would probably be best to explore a different form of advertising. In summary, we used machine learning (specifically, linear regression) to predict how much revenue a TV advertising campaign would generate, based on historical data.IoT For All NewsletterSign up for our weekly newsletter and exclusive content!2. Credit Card Example (Logistic Regression)In the previous example, we mapped a numeric input (TV ad spending) to a numericoutput (sales). However, it is also acceptable for the inputs/output to be categorical. When the output variable is categorical, then it is called a classification algorithm.For example, a credit card company might want to predict whether a customer will default in the upcoming 3 months based on their current balance. Here, the output variable is categorical: it is either “yes” (the customer defaulted) or “no” (the customer did not default). As with the previous example, we need access to a dataset with labels that tell us whether or not the customer defaulted. We can then apply a classification algorithm like logistic regression.The algorithm produces a more complex equation (red line) than linear regression. Previously, we were trying to predict an actual number (sales) so the output of our formula was a number ($11.73). However, we are no longer predicting a number. Instead we are predicting a category (“Yes, they will default within 3 months” or “No, they won’t default”).The red line in the graph above represents the probability that someone will default based on their current balance. When a customer’s balance is less than 1000, the probability of default (red line) is near 0 (e.g. very unlikely to default). As a customer’s balance increases, so does the chances of default. We plotted the historical data in the graph as well, with “Yes” and “No” dummy coded as 1 and 0, respectively.This equation can help you make predictions about new customers, where you aren’t told whether or not they will default in advance. From the logistic regression equation, you could check their balance, see that it’s only $400, and safely conclude they probably won’t default in three months. On the other hand, if their balance was $2500, you would know that they’re extremely likely to.ConclusionSo far we’ve covered supervised machine learning, where we make predictions from labeled historical data. Stay tuned for the next part in the series where we cover unsupervised and reinforcement learning.🗓 This article was originally published on iotforall.com on November 1, 2017.Want all the latest advances and tech news sent directly to your\\xa0inbox?Machine LearningDeep LearningIoTTechNewsOne clap, two clap, three clap, forty?By clapping more or less, you can signal to us which stories really stand out.Narin LuangrathProduct Engineer at Leverege LLCIoT For AllExpert analysis, simple explanations, and the latest advances in IoT, AR/VR/MR, AI & ML and beyond! To publish with us please email: contribute@iotforall.com'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the nth value from the corpus to confirm \n",
    "import itertools\n",
    "index = 3302\n",
    "mycorpus.get_nth(index)\n",
    "# next(itertools.islice(mycorpus.get_nth(), index, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary & corpus\n",
    "dictionary.save('./models/dictionary/sample10000Dict')\n",
    "corpora.MmCorpus.serialize(f'./models/sample10000corpus.mm', bowcorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tfidf model \n",
    "tfidf_model.save('./models/tfidf-sample10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LDA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('./models/lda-sample10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.02464313e-05, 6.57749126e-07, 1.33015255e-05, ...,\n",
       "        6.57749126e-07, 6.57749126e-07, 6.57749126e-07],\n",
       "       [9.72484122e-05, 1.18829234e-06, 7.61081465e-04, ...,\n",
       "        1.18829234e-06, 1.18829234e-06, 1.18829234e-06],\n",
       "       [1.74260465e-03, 5.97335728e-08, 6.22376688e-02, ...,\n",
       "        5.97335728e-08, 5.97335728e-08, 5.97335728e-08],\n",
       "       ...,\n",
       "       [1.37718511e-03, 6.86899781e-09, 6.97344367e-05, ...,\n",
       "        6.86899781e-09, 6.86899781e-09, 6.86899781e-09],\n",
       "       [1.71955598e-05, 1.16311571e-06, 3.88967601e-06, ...,\n",
       "        1.16311571e-06, 1.16311571e-06, 1.16311571e-06],\n",
       "       [3.36568832e-04, 6.13788700e-07, 1.16003896e-04, ...,\n",
       "        5.41717270e-07, 5.41717270e-07, 5.41717270e-07]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Recommendations for a User "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a User profile \n",
    "* We will use the context of the class \n",
    "* Get all liked/added articles\n",
    "* Create a combinded text of the top 3 and most recent 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
